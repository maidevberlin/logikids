server:
  port: 3000

ai:
  # Available providers: 'ollama', 'openai', or 'anthropic'
  provider: ollama

  # ═══════════════════════════════════════════════════════════════════════
  # NOTE: API keys are configured via environment variables (.env file),
  #       NOT in this config file. Run ./setup.sh to configure them.
  # ═══════════════════════════════════════════════════════════════════════

  # Ollama Configuration (required if provider is 'ollama')
  ollama:
    host: http://host.docker.internal:11434
    model: llama3-8b
  # High Performance Models (Requires powerful hardware):
  # - mixtral-8x7b: Best overall performance and reasoning capabilities
  # - llama3-70b: Excellent for educational content (needs >50GB RAM)
  # - qwen2.5-72b: Great for complex reasoning (needs >50GB RAM)
  #
  # Standard Models (Recommended for most users):
  # - llama3-8b: Good balance of performance and resource usage
  # - qwen2.5-7b: Efficient for educational tasks
  # - gemma2-7b: Reliable for structured content
  # - phi4-14b: Specialized in mathematical reasoning


  # OpenAI Configuration (required if provider is 'openai')
  # API key: Set OPENAI_API_KEY in .env
  openai:
    model: gpt-4o
  # Latest Models (2025):
  # - gpt-5: Most advanced model, best for complex educational content
  # - gpt-5-mini: Fast and affordable, great balance for most tasks
  # - gpt-4.1: Improved coding and instruction-following, cost-effective
  # - gpt-4o: Multimodal model, good all-around performance

  # Anthropic Configuration (required if provider is 'anthropic')
  # API key: Set ANTHROPIC_API_KEY in .env
  anthropic:
    model: claude-sonnet-4-5
    maxTokens: 4096
    temperature: 0.7
  # Available Models (2025):
  # - claude-sonnet-4-5: Latest, best for coding and complex tasks
  # - claude-haiku-4-5: Fastest model, great for simple tasks
  # - claude-3-5-sonnet: Previous generation, still very capable
  # - claude-3-opus: Most capable Claude 3 model
